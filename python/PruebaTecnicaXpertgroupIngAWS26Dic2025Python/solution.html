<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Estrategias de Solución y Arquitectura</title>
  <style>
  body { font-family: 'Segoe UI', Arial, sans-serif; background: #fafbfc; color: #23272f; margin: 0; padding: 0; }
  .container { max-width: 980px; margin: 40px auto; background: #fff; box-shadow: 0 8px 32px rgba(0,0,0,0.08); border-radius: 10px; padding: 32px 40px; }
  h1 { color: #1565c0; }
  h2 { color: #2e7d32; margin-top: 32px; }
  h3 { color: #7b1fa2; margin-top: 24px; }
  .section { margin-top: 24px; }
  .note { background: #e3f2fd; border-left: 4px solid #1976d2; padding: 16px 20px; margin: 18px 0; border-radius: 7px; }
  ul { padding-left: 1.4em; }
  .row { display:flex; gap:24px; flex-wrap:wrap; margin-top: 16px; }
  .card { flex:1 1 320px; border: 1px solid #e0e0e0; border-radius: 10px; padding: 20px; background: #fff; box-shadow: 0 4px 12px rgba(0,0,0,0.04); }
  .footer { text-align: right; color: #888; font-size: 0.95em; margin-top: 24px; }
  pre { background: #f6f8fa; padding: 12px; border-radius: 8px; overflow: auto; }
  @media (max-width: 600px) { .row { flex-direction: column; } }
  </style>
</head>
<body>
  <div class="container">
    <h1>Estrategias de solución en Python</h1>
    <p>El pipeline comienza desde el JSON <code>dataset_hospital 2 AWS.json</code>. Se propone el siguiente modelo por capas para asegurar limpieza, validación y entrega de tablas limpias.</p>

    <div class="section">
      <h2>1. Ingesta y perfilado inicial</h2>
      <ul>
        <li><strong>Pandas + pathlib.</strong> Leer el JSON con <code>pd.read_json()</code> apuntando a cada tabla y establecer tipos básicos (int, datetime, category) para reducir sorpresas.</li>
        <li>Perfilado con <code>pandas_profiling</code> o <code>dataprep.eda</code> para identificar nulos, duplicados y distribuciones, generando reportes HTML.</li>
        <li>Registrar métricas iniciales de completitud/validez por campo en un artefacto (CSV o JSON).</li>
      </ul>
    </div>

    <div class="section">
      <h2>2. Transformaciones y limpieza</h2>
      <ul>
        <li>Normalizar texto (strip, lower, eliminar tildes) para campos como <code>nombre</code>, <code>ciudad</code> y <code>especialidad</code>.</li>
        <li>Imputar edades faltantes con la diferencia entre la fecha de corte y <code>fecha_nacimiento</code>; si la fecha falta, dejar <code>edad</code> como <code>NaN</code> y documentar la restricción.</li>
        <li>Interpolar contactos (correo/teléfono) dejando registros preparados para validación externa y marcando campos con <code>missing_contact</code> para seguimiento.</li>
        <li>Eliminar duplicados por <code>id_paciente</code> y consolidar los registros con preferencia por los valores no nulos recientes.</li>
      </ul>
    </div>

    <div class="section">
      <h2>3. Validaciones cruzadas</h2>
      <ul>
        <li>Usar <code>pandas.merge()</code> para validar que cada <code>id_paciente</code> de citas exista en <code>pacientes</code>; los huérfanos se exportan a un CSV de discrepancias.</li>
        <li>Validar estados válidos en <code>estado_cita</code> con un <code>Enum</code> (p.ej., {Completada, Cancelada, Reprogramada}).</li>
        <li>Verificar que citas con estado completado tengan fecha y médico no nulos, generando un registro de errores si no.</li>
        <li>Calcular edad real (de fecha) y comparar con la registrada para detectar errores de captura, complementado con un reporte de diferencias.</li>
      </ul>
    </div>

    <div class="section">
      <h2>4. Métricas antes y después</h2>
      <ul>
        <li>Definir función que calcule completitud, unicidad, y porcentaje de datos válidos por campo (pre y post limpieza) y escriba resultados en <code>reports/metrics.json</code>.</li>
        <li>Comparar recuentos de citas por especialidad antes y después para asegurar que no se perdieron filas.</li>
        <li>Guardar muestras de registros corregidos junto a notas sobre las reglas aplicadas para documentar supuestos.</li>
      </ul>
    </div>

    <div class="section">
      <h2>5. Exportación y pruebas</h2>
      <ul>
        <li>Exportar tablas limpias a <code>.csv</code> o <code>.parquet</code> en carpetas con timestamp (por ejemplo: <code>outputs/pacientes/</code>).</li>
        <li>Crear pruebas automáticas usando <code>pytest</code> y <code>great_expectations</code> para cubrir: tipos contrato, integridad referencial, no null en campos críticos.</li>
        <li>Agregar un script que invoque cada validación y falle con código distinto si se detecta violación.</li>
      </ul>
    </div>

    <div class="section">
      <h2>6. Supuestos documentados</h2>
      <ul>
        <li>Se asume que <code>id_paciente</code> es clave primaria y no se debe duplicar a menos que se consoliden datos.</li>
        <li>Las fechas sin valor se consideran incompletas y deben pasar por análisis manual antes de generar indicadores.</li>
        <li>Las reglas de negocio (estados válidos, rangos de edad) se guardan en un archivo <code>rules.yaml</code> para mantener trazabilidad.</li>
      </ul>
    </div>

    <h1 class="section">Arquitectura propuesta</h1>
    <div class="row">
      <div class="card">
        <h3>Ingesta</h3>
        <p>Archivo JSON (descargado manual o desde S3). Un script Python programado (cron o Airflow) lee el fichero, lo valida y escribe tablas intermedias.</p>
      </div>
      <div class="card">
        <h3>Limpieza / Validación</h3>
        <p>Pandas + Great Expectations + funciones propias (p.ej., <code>validate_citas()</code>). Se registra cada transformación y se generan reportes HTML/JSON.</p>
      </div>
    </div>

    <div class="row">
      <div class="card">
        <h3>Storage</h3>
        <p>Versionamiento en carpetas organizadas por fecha en el repositorio (<code>outputs/{tabla}/{timestamp}/</code>) o en un bucket de datos si se escala.</p>
      </div>
      <div class="card">
        <h3>Governance & Reporting</h3>
        <p>Métricas de calidad almacenadas en <code>reports/metrics.json</code> y dashboards con Power BI o herramientas open source usando csv/parquet generados.</p>
      </div>
    </div>

    <div class="row">
      <div class="card">
        <h3>Orquestación</h3>
        <p>Airflow o Prefect para encadenar pasos: ingestión → limpieza → validaciones → exportación → pruebas automáticas.</p>
      </div>
      <div class="card">
        <h3>Entrega</h3>
        <p>Exportar datasets limpios, reportes y pruebas en un ZIP, junto al informe PDF para cumplir con requisitos de la prueba técnica.</p>
      </div>
    </div>

    <div class="note">
      <p>Esta propuesta se puede implementar como script monolítico o a través de notebooks modulares, siempre dejando artefactos (logs, métricas) que respalden las decisiones.</p>
    </div>

    <div class="footer">
      Estrategia pensada para escalar a un entorno productivo manteniendo trazabilidad y prueba continua.
    </div>
  </div>
</body>
</html>
